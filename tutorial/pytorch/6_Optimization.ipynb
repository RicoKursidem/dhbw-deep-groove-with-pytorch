{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTopch\n",
    "\n",
    "## OPTIMIZING MODEL PARAMETERS\n",
    "\n",
    "iteration = epoch\n",
    "\n",
    "### Prerequisite Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0118, 0.0039, 0.0000, 0.0000, 0.0275,\n",
      "          0.0000, 0.1451, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0078, 0.0000,\n",
      "          0.1059, 0.3294, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.4667, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
      "          0.3451, 0.5608, 0.4314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863,\n",
      "          0.3647, 0.4157, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.2078,\n",
      "          0.5059, 0.4706, 0.5765, 0.6863, 0.6157, 0.6510, 0.5294, 0.6039,\n",
      "          0.6588, 0.5490, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0431, 0.5373,\n",
      "          0.5098, 0.5020, 0.6275, 0.6902, 0.6235, 0.6549, 0.6980, 0.5843,\n",
      "          0.5922, 0.5647, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
      "          0.0078, 0.0039, 0.0000, 0.0118, 0.0000, 0.0000, 0.4510, 0.4471,\n",
      "          0.4157, 0.5373, 0.6588, 0.6000, 0.6118, 0.6471, 0.6549, 0.5608,\n",
      "          0.6157, 0.6196, 0.0431, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0118, 0.0000, 0.0000, 0.3490, 0.5451, 0.3529,\n",
      "          0.3686, 0.6000, 0.5843, 0.5137, 0.5922, 0.6627, 0.6745, 0.5608,\n",
      "          0.6235, 0.6627, 0.1882, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0157,\n",
      "          0.0039, 0.0000, 0.0000, 0.0000, 0.3843, 0.5333, 0.4314, 0.4275,\n",
      "          0.4314, 0.6353, 0.5294, 0.5647, 0.5843, 0.6235, 0.6549, 0.5647,\n",
      "          0.6196, 0.6627, 0.4667, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0078, 0.0078, 0.0039, 0.0078, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1020, 0.4235, 0.4588, 0.3882, 0.4353, 0.4588,\n",
      "          0.5333, 0.6118, 0.5255, 0.6039, 0.6039, 0.6118, 0.6275, 0.5529,\n",
      "          0.5765, 0.6118, 0.6980, 0.0000],\n",
      "         [0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824,\n",
      "          0.2078, 0.3608, 0.4588, 0.4353, 0.4039, 0.4510, 0.5059, 0.5255,\n",
      "          0.5608, 0.6039, 0.6471, 0.6667, 0.6039, 0.5922, 0.6039, 0.5608,\n",
      "          0.5412, 0.5882, 0.6471, 0.1686],\n",
      "         [0.0000, 0.0000, 0.0902, 0.2118, 0.2549, 0.2980, 0.3333, 0.4627,\n",
      "          0.5020, 0.4824, 0.4353, 0.4431, 0.4627, 0.4980, 0.4902, 0.5451,\n",
      "          0.5216, 0.5333, 0.6275, 0.5490, 0.6078, 0.6314, 0.5647, 0.6078,\n",
      "          0.6745, 0.6314, 0.7412, 0.2431],\n",
      "         [0.0000, 0.2667, 0.3686, 0.3529, 0.4353, 0.4471, 0.4353, 0.4471,\n",
      "          0.4510, 0.4980, 0.5294, 0.5333, 0.5608, 0.4941, 0.4980, 0.5922,\n",
      "          0.6039, 0.5608, 0.5804, 0.4902, 0.6353, 0.6353, 0.5647, 0.5412,\n",
      "          0.6000, 0.6353, 0.7686, 0.2275],\n",
      "         [0.2745, 0.6627, 0.5059, 0.4078, 0.3843, 0.3922, 0.3686, 0.3804,\n",
      "          0.3843, 0.4000, 0.4235, 0.4157, 0.4667, 0.4706, 0.5059, 0.5843,\n",
      "          0.6118, 0.6549, 0.7451, 0.7451, 0.7686, 0.7765, 0.7765, 0.7333,\n",
      "          0.7725, 0.7412, 0.7216, 0.1412],\n",
      "         [0.0627, 0.4941, 0.6706, 0.7373, 0.7373, 0.7216, 0.6706, 0.6000,\n",
      "          0.5294, 0.4706, 0.4941, 0.4980, 0.5725, 0.7255, 0.7647, 0.8196,\n",
      "          0.8157, 1.0000, 0.8196, 0.6941, 0.9608, 0.9882, 0.9843, 0.9843,\n",
      "          0.9686, 0.8627, 0.8078, 0.1922],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0471, 0.2627, 0.4157, 0.6431, 0.7255,\n",
      "          0.7804, 0.8235, 0.8275, 0.8235, 0.8157, 0.7451, 0.5882, 0.3216,\n",
      "          0.0314, 0.0000, 0.0000, 0.0000, 0.6980, 0.8157, 0.7373, 0.6863,\n",
      "          0.6353, 0.6196, 0.5922, 0.0431],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]]) 9\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0510, 0.2627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1961, 0.1490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314,\n",
      "          0.4706, 0.8196, 0.8863, 0.9686, 0.9294, 1.0000, 1.0000, 1.0000,\n",
      "          0.9686, 0.9333, 0.9216, 0.6745, 0.2824, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5373, 0.9373,\n",
      "          0.9882, 0.9529, 0.9176, 0.8980, 0.9333, 0.9569, 0.9647, 0.9412,\n",
      "          0.9020, 0.9098, 0.9373, 0.9725, 0.9843, 0.7608, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4000, 1.0000, 0.9059,\n",
      "          0.8941, 0.8902, 0.8941, 0.9137, 0.9020, 0.9020, 0.8980, 0.8941,\n",
      "          0.9098, 0.9098, 0.9059, 0.8902, 0.8784, 0.9882, 0.7020, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9137, 0.9451, 0.8980,\n",
      "          0.9059, 1.0000, 1.0000, 0.9333, 0.9059, 0.8902, 0.9333, 0.9647,\n",
      "          0.8941, 0.9020, 0.8902, 0.9176, 0.9216, 0.8980, 0.9451, 0.0784,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9725, 0.9451, 0.9059,\n",
      "          1.0000, 0.5843, 0.1843, 0.9882, 0.8941, 1.0000, 0.9490, 0.8471,\n",
      "          0.9333, 0.9098, 1.0000, 0.8941, 0.8627, 0.9176, 0.9804, 0.2118,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9412, 0.9098,\n",
      "          1.0000, 0.0588, 0.0000, 1.0000, 0.9294, 0.7490, 0.0000, 0.0000,\n",
      "          0.8392, 1.0000, 0.0510, 0.4824, 1.0000, 0.9176, 0.9882, 0.4471,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 1.0000, 0.9333, 0.9373,\n",
      "          1.0000, 0.6941, 0.0000, 1.0000, 1.0000, 0.0000, 0.5098, 0.4549,\n",
      "          0.1843, 0.2549, 0.1686, 0.1451, 1.0000, 0.9255, 0.9765, 0.6353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.1255, 1.0000, 0.9255, 0.9608,\n",
      "          1.0000, 0.8000, 0.0000, 1.0000, 0.3294, 0.0000, 0.1451, 0.1098,\n",
      "          0.1216, 0.0000, 0.0980, 0.0510, 1.0000, 0.9255, 0.9765, 0.7804,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2078, 1.0000, 0.9255, 0.9804,\n",
      "          0.9804, 0.9059, 0.0078, 1.0000, 0.0824, 0.0000, 0.8667, 1.0000,\n",
      "          0.9255, 0.2118, 0.9608, 0.7765, 0.9529, 0.9333, 0.9608, 0.8745,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.3137, 1.0000, 0.9294, 0.9804,\n",
      "          0.9412, 1.0000, 0.0000, 0.0000, 0.1529, 0.6157, 0.0000, 0.0000,\n",
      "          0.8431, 0.3686, 0.0784, 0.4941, 1.0000, 0.9294, 0.9373, 0.9804,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.3961, 1.0000, 0.9216, 0.9922,\n",
      "          0.9569, 0.9529, 0.5216, 0.5412, 0.8157, 1.0000, 0.7882, 0.8392,\n",
      "          1.0000, 0.9020, 0.0275, 0.6824, 1.0000, 0.9412, 0.9333, 1.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 1.0000, 0.9137, 1.0000,\n",
      "          0.9725, 0.9137, 1.0000, 1.0000, 0.9412, 0.9098, 0.9529, 0.9529,\n",
      "          0.9059, 0.9843, 1.0000, 1.0000, 0.9961, 0.9529, 0.9333, 1.0000,\n",
      "          0.0118, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5765, 1.0000, 0.9137, 0.9765,\n",
      "          0.7098, 0.9529, 0.8902, 0.8784, 0.9020, 0.9176, 0.9020, 0.9020,\n",
      "          0.9216, 0.8941, 0.9216, 0.8706, 0.8118, 1.0000, 0.9255, 1.0000,\n",
      "          0.1373, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.6392, 1.0000, 0.9608, 0.8667,\n",
      "          0.3373, 1.0000, 0.9137, 0.9137, 0.9216, 0.9255, 0.9176, 0.9176,\n",
      "          0.9176, 0.9098, 0.9490, 0.9059, 0.4902, 1.0000, 0.9255, 1.0000,\n",
      "          0.2157, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.7098, 0.9961, 1.0000, 0.7843,\n",
      "          0.2706, 1.0000, 0.8941, 0.9098, 0.9176, 0.9216, 0.9176, 0.9176,\n",
      "          0.9137, 0.9216, 0.9451, 0.9294, 0.2745, 1.0000, 0.9216, 0.9647,\n",
      "          0.2235, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.7725, 0.9686, 1.0000, 0.7373,\n",
      "          0.4314, 1.0000, 0.8784, 0.9137, 0.9176, 0.9176, 0.9176, 0.9176,\n",
      "          0.9176, 0.9176, 0.9412, 0.9922, 0.2706, 1.0000, 0.9255, 0.9725,\n",
      "          0.3020, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.7843, 0.9647, 1.0000, 0.5843,\n",
      "          0.5686, 1.0000, 0.8745, 0.9216, 0.9176, 0.9216, 0.9216, 0.9216,\n",
      "          0.9176, 0.9294, 0.9137, 1.0000, 0.1843, 1.0000, 0.9373, 0.9765,\n",
      "          0.3843, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.8000, 0.9529, 1.0000, 0.4353,\n",
      "          0.6784, 1.0000, 0.8902, 0.9216, 0.9216, 0.9255, 0.9216, 0.9216,\n",
      "          0.9216, 0.9373, 0.8980, 1.0000, 0.0745, 0.8902, 0.9647, 0.9765,\n",
      "          0.4314, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.7686, 0.9412, 1.0000, 0.4275,\n",
      "          0.8353, 0.9804, 0.8980, 0.9216, 0.9216, 0.9255, 0.9216, 0.9294,\n",
      "          0.9255, 0.9294, 0.8863, 1.0000, 0.2157, 0.7961, 0.9843, 0.9608,\n",
      "          0.4706, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.7529, 0.9529, 1.0000, 0.4471,\n",
      "          0.9098, 0.9412, 0.9098, 0.9216, 0.9216, 0.9255, 0.9176, 0.9294,\n",
      "          0.9255, 0.9216, 0.8980, 1.0000, 0.5255, 0.6706, 0.9882, 0.9569,\n",
      "          0.5373, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.7412, 0.9843, 1.0000, 0.6039,\n",
      "          0.9333, 0.9137, 0.9255, 0.9176, 0.9216, 0.9255, 0.9216, 0.9333,\n",
      "          0.9255, 0.9216, 0.9098, 1.0000, 0.6510, 0.4902, 1.0000, 0.9529,\n",
      "          0.5569, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.9882, 1.0000, 0.6706,\n",
      "          0.9686, 0.9098, 0.9176, 0.9176, 0.9137, 0.9137, 0.9098, 0.9176,\n",
      "          0.9137, 0.9176, 0.9137, 0.9412, 0.8745, 0.5020, 1.0000, 0.9490,\n",
      "          0.5922, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.6980, 0.9529, 1.0000, 0.2235,\n",
      "          0.9333, 0.9451, 0.9333, 0.9333, 0.9333, 0.9294, 0.9255, 0.9294,\n",
      "          0.9294, 0.9412, 0.9294, 0.9961, 0.6902, 0.2039, 1.0000, 0.9373,\n",
      "          0.6157, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.7373, 0.9412, 0.9804, 0.2431,\n",
      "          0.8549, 1.0000, 0.8627, 0.8706, 0.8706, 0.8706, 0.8745, 0.8745,\n",
      "          0.8784, 0.8706, 0.8549, 1.0000, 0.6039, 0.1255, 1.0000, 0.9255,\n",
      "          0.7373, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5098, 0.9608, 0.9490, 0.0941,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1333, 0.9490, 0.9569,\n",
      "          0.5294, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2980, 1.0000, 0.9765, 0.0863,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.9765, 1.0000,\n",
      "          0.4824, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.8039, 0.7725, 0.0431,\n",
      "          0.0000, 0.0157, 0.0039, 0.0078, 0.0078, 0.0078, 0.0078, 0.0078,\n",
      "          0.0078, 0.0078, 0.0078, 0.0118, 0.0000, 0.0118, 0.6824, 0.7412,\n",
      "          0.2627, 0.0000, 0.0000, 0.0000]]]) 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "count = 1\n",
    "for i, (data, labels) in enumerate(test_data):\n",
    "    print(data, labels)\n",
    "    if i == count: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x25e8a60ac80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "train_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x25e8a60ad70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.301803  [    0/60000]\n",
      "loss: 2.294969  [ 6400/60000]\n",
      "loss: 2.272023  [12800/60000]\n",
      "loss: 2.269530  [19200/60000]\n",
      "loss: 2.248840  [25600/60000]\n",
      "loss: 2.221572  [32000/60000]\n",
      "loss: 2.222413  [38400/60000]\n",
      "loss: 2.188668  [44800/60000]\n",
      "loss: 2.188517  [51200/60000]\n",
      "loss: 2.161980  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.150440 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.157990  [    0/60000]\n",
      "loss: 2.152672  [ 6400/60000]\n",
      "loss: 2.087654  [12800/60000]\n",
      "loss: 2.108992  [19200/60000]\n",
      "loss: 2.062240  [25600/60000]\n",
      "loss: 2.004831  [32000/60000]\n",
      "loss: 2.025261  [38400/60000]\n",
      "loss: 1.943721  [44800/60000]\n",
      "loss: 1.950858  [51200/60000]\n",
      "loss: 1.886865  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 1.877396 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.908485  [    0/60000]\n",
      "loss: 1.882144  [ 6400/60000]\n",
      "loss: 1.755992  [12800/60000]\n",
      "loss: 1.801304  [19200/60000]\n",
      "loss: 1.701795  [25600/60000]\n",
      "loss: 1.653601  [32000/60000]\n",
      "loss: 1.668764  [38400/60000]\n",
      "loss: 1.570384  [44800/60000]\n",
      "loss: 1.595442  [51200/60000]\n",
      "loss: 1.492955  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 1.511113 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.576030  [    0/60000]\n",
      "loss: 1.544241  [ 6400/60000]\n",
      "loss: 1.389933  [12800/60000]\n",
      "loss: 1.467161  [19200/60000]\n",
      "loss: 1.354127  [25600/60000]\n",
      "loss: 1.351577  [32000/60000]\n",
      "loss: 1.361212  [38400/60000]\n",
      "loss: 1.288964  [44800/60000]\n",
      "loss: 1.322416  [51200/60000]\n",
      "loss: 1.220993  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 1.251481 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.329577  [    0/60000]\n",
      "loss: 1.310428  [ 6400/60000]\n",
      "loss: 1.142909  [12800/60000]\n",
      "loss: 1.250248  [19200/60000]\n",
      "loss: 1.129175  [25600/60000]\n",
      "loss: 1.158117  [32000/60000]\n",
      "loss: 1.174253  [38400/60000]\n",
      "loss: 1.115716  [44800/60000]\n",
      "loss: 1.151395  [51200/60000]\n",
      "loss: 1.064144  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.089698 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.164632  [    0/60000]\n",
      "loss: 1.163613  [ 6400/60000]\n",
      "loss: 0.979679  [12800/60000]\n",
      "loss: 1.113654  [19200/60000]\n",
      "loss: 0.989625  [25600/60000]\n",
      "loss: 1.027597  [32000/60000]\n",
      "loss: 1.057376  [38400/60000]\n",
      "loss: 1.003719  [44800/60000]\n",
      "loss: 1.038151  [51200/60000]\n",
      "loss: 0.965064  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.984237 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.048252  [    0/60000]\n",
      "loss: 1.068099  [ 6400/60000]\n",
      "loss: 0.866763  [12800/60000]\n",
      "loss: 1.021995  [19200/60000]\n",
      "loss: 0.900693  [25600/60000]\n",
      "loss: 0.934868  [32000/60000]\n",
      "loss: 0.979880  [38400/60000]\n",
      "loss: 0.930033  [44800/60000]\n",
      "loss: 0.959246  [51200/60000]\n",
      "loss: 0.897924  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.912202 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.962542  [    0/60000]\n",
      "loss: 1.001504  [ 6400/60000]\n",
      "loss: 0.785682  [12800/60000]\n",
      "loss: 0.957454  [19200/60000]\n",
      "loss: 0.841036  [25600/60000]\n",
      "loss: 0.867095  [32000/60000]\n",
      "loss: 0.924690  [38400/60000]\n",
      "loss: 0.880227  [44800/60000]\n",
      "loss: 0.902560  [51200/60000]\n",
      "loss: 0.849634  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.860356 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.896618  [    0/60000]\n",
      "loss: 0.951345  [ 6400/60000]\n",
      "loss: 0.724990  [12800/60000]\n",
      "loss: 0.909533  [19200/60000]\n",
      "loss: 0.798649  [25600/60000]\n",
      "loss: 0.816196  [32000/60000]\n",
      "loss: 0.882603  [38400/60000]\n",
      "loss: 0.845088  [44800/60000]\n",
      "loss: 0.860391  [51200/60000]\n",
      "loss: 0.812885  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.821201 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.844002  [    0/60000]\n",
      "loss: 0.911113  [ 6400/60000]\n",
      "loss: 0.677564  [12800/60000]\n",
      "loss: 0.872453  [19200/60000]\n",
      "loss: 0.766550  [25600/60000]\n",
      "loss: 0.777164  [32000/60000]\n",
      "loss: 0.848580  [38400/60000]\n",
      "loss: 0.818892  [44800/60000]\n",
      "loss: 0.827673  [51200/60000]\n",
      "loss: 0.783224  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.790185 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6136afe9ac920a5fa1b4f85d7114e3fcf8507f6837d1054cc1ed4ea467060c55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
